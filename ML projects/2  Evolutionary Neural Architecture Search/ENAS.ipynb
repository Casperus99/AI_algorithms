{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENAS ALGORITHM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.layer_utils import count_params\n",
    "from random import randint, choice, choices, random, sample\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30000, 28, 28, 1)\n",
      "30000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\")[::2] / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train[::2], num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEAT_SIZES = (2, 4, 6, 10, 14, 22, 30, 46, 62)\n",
    "MAX_KERPOOL_SIZE = 5 #Maximum kernel and pool size\n",
    "# MAX_STRIDE_SIZE = 2\n",
    "MAX_BLOCK_SIZE = 3 #Maximum conv layers in VGG block\n",
    "MAX_NETWORK_SIZE = 3 #Maimum blocks in network\n",
    "ACTIVATIONS = ['relu', 'sigmoid', 'tanh']\n",
    "\n",
    "BEST_LIMIT = 5 #How many best individuals shuld be saved\n",
    "\n",
    "MUT_PROB = 0.5 #Basic mutation probability\n",
    "LAY_PROB = 0.4 #Chance to add or delete a layer in the block\n",
    "BLOCK_PROB = 0.3 #Chance to add or delete a block in the network\n",
    "\n",
    "BACH_SIZE = 128\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.feature_size = choice(FEAT_SIZES)\n",
    "        self.kernel_size_x = randint(1, MAX_KERPOOL_SIZE)\n",
    "        self.kernel_size_y = randint(1, MAX_KERPOOL_SIZE)\n",
    "        self.activation = choice(ACTIVATIONS)\n",
    "        # To prevent 1x1 kernel size\n",
    "        while self.kernel_size_x == 1 and self.kernel_size_y == 1:\n",
    "            self.kernel_size_x = randint(1, MAX_KERPOOL_SIZE)\n",
    "            self.kernel_size_y = randint(1, MAX_KERPOOL_SIZE)\n",
    "        # self.kernel_stride_x = randint(1, MAX_KERPOOL_SIZE)\n",
    "        # self.kernel_stride_y = randint(1, MAX_KERPOOL_SIZE)\n",
    "\n",
    "    def layer(self, model):\n",
    "        model.add(layers.Conv2D(self.feature_size, kernel_size=(self.kernel_size_x, self.kernel_size_y), padding='same'))\n",
    "        # model.add(layers.BatchNormalization(axis=1))\n",
    "        model.add(layers.Activation(activation=self.activation))\n",
    "        # model.add(layers.Dropout(0.5))\n",
    "\n",
    "    def mutate(self):\n",
    "        for key, value in vars(self).items():\n",
    "            if key == 'feature_size':\n",
    "                rand = random()\n",
    "            if rand < MUT_PROB:\n",
    "                if key == 'feature_size':\n",
    "                    # So it changes even if on the varge of the range\n",
    "                    index = FEAT_SIZES.index(value)\n",
    "                    if index == 0:\n",
    "                        jump = 1\n",
    "                    elif index == len(FEAT_SIZES)-1:\n",
    "                        jump = -1\n",
    "                    else:\n",
    "                        jump = choice([-1,1])\n",
    "                    self.feature_size = FEAT_SIZES[index+jump]\n",
    "                elif key == 'activation':\n",
    "                    # It cannot pick the same function\n",
    "                    act_list = copy.deepcopy(ACTIVATIONS)\n",
    "                    act_list.remove(self.activation)\n",
    "                    self.activation = choice(act_list)\n",
    "                else:\n",
    "                    # So it changes even if on the varge of the range\n",
    "                    if value == 1:\n",
    "                        jump = 1\n",
    "                    elif value == MAX_KERPOOL_SIZE:\n",
    "                        jump = -1\n",
    "                    else:\n",
    "                        jump = choice([-1, 1])\n",
    "                    vars(self)[key] = value + jump\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pooling layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoolingLayer():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pool_size_x = randint(2, MAX_KERPOOL_SIZE)\n",
    "        self.pool_size_y = randint(2, MAX_KERPOOL_SIZE)\n",
    "        self.pool_type = choice(['max', 'avg'])\n",
    "        # self.pool_stride_x = randint(1, MAX_KERPOOL_SIZE)\n",
    "        # self.pool_stride_y = randint(1, MAX_KERPOOL_SIZE)\n",
    "\n",
    "    def layer(self):\n",
    "        if self.pool_type == 'max':\n",
    "            return layers.MaxPooling2D(pool_size=(self.pool_size_x, self.pool_size_y), strides=(2, 2))\n",
    "        elif self.pool_type == 'avg':\n",
    "            return layers.AveragePooling2D(pool_size=(self.pool_size_x, self.pool_size_y), strides=(2, 2))\n",
    "\n",
    "    def mutate(self):\n",
    "        for key, value in vars(self).items():\n",
    "            if random() < MUT_PROB:\n",
    "                if key == 'pool_type':\n",
    "                    if value == 'max':\n",
    "                        self.pool_type = 'avg'\n",
    "                    else:\n",
    "                        self.pool_type = 'max'\n",
    "                else:\n",
    "                    # So it changes even if on the varge of the range\n",
    "                    if value == 1:\n",
    "                        jump = 1\n",
    "                    elif value == MAX_KERPOOL_SIZE:\n",
    "                        jump = -1\n",
    "                    else:\n",
    "                        jump = choice([-1, 1])\n",
    "                    vars(self)[key] = value + jump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VGG block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.convs = [ConvLayer() for _ in range(randint(1, MAX_BLOCK_SIZE))]\n",
    "        self.pooling = PoolingLayer()\n",
    "        \n",
    "    def block(self, model):\n",
    "        for layer in self.convs:\n",
    "            layer.layer(model)\n",
    "        model.add(self.pooling.layer())\n",
    "\n",
    "    def mutate(self):\n",
    "        size = len(self.convs)\n",
    "        rand = random()\n",
    "        if rand < LAY_PROB:\n",
    "            jump = choice([-1,1])\n",
    "            if size == MAX_BLOCK_SIZE or (jump == -1 and size > 1):\n",
    "                self.convs.remove((choice(self.convs)))\n",
    "            if size == 1 or (jump == 1 and size < MAX_BLOCK_SIZE):\n",
    "                self.convs.insert(randint(0, size), ConvLayer())\n",
    "            self.pooling.mutate()\n",
    "        [layer.mutate() for layer in self.convs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    \n",
    "    def __init__(self, blocks=None):\n",
    "        if blocks is None:\n",
    "            self.blocks = [ConvBlock() for _ in range(randint(1, MAX_NETWORK_SIZE))]\n",
    "        else:\n",
    "            self.blocks = blocks[0]\n",
    "            [self.blocks.append(block) for block in blocks[1]]\n",
    "\n",
    "    def evaluate(self):\n",
    "        print([[layer.feature_size for layer in block.convs] for block in self.blocks])\n",
    "        model = keras.Sequential([keras.Input(shape=input_shape)])\n",
    "        [block.block(model) for block in self.blocks]\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(num_classes))\n",
    "        model.add(layers.BatchNormalization(axis=1))\n",
    "        model.add(layers.Activation(activation='softmax'))\n",
    "\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "        trainable_params = count_params(model.trainable_weights)\n",
    "        \n",
    "        history = model.fit(x_train, y_train, batch_size=BACH_SIZE, epochs=EPOCHS, validation_split=0.2, verbose=0)\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        \n",
    "        self.val_score = history.history['val_accuracy'][EPOCHS-1] - (3**((0.5*trainable_params+30000)/5000))/15000000\n",
    "        self.test_score = score[1] - (3**((0.5*trainable_params+30000)/5000))/15000000\n",
    "\n",
    "    def mutate(self):\n",
    "        size = len(self.blocks)\n",
    "        rand = random()\n",
    "        if rand < BLOCK_PROB:\n",
    "            jump = choice([-1,1])\n",
    "            if size == MAX_NETWORK_SIZE or (jump == -1 and size != 1):\n",
    "                self.blocks.remove((choice(self.blocks)))\n",
    "            if size == 1 or (jump == 1 and size != MAX_NETWORK_SIZE):\n",
    "                self.blocks.insert(randint(0, size), ConvBlock())\n",
    "        [block.mutate() for block in self.blocks]\n",
    "\n",
    "    def print_info(self):\n",
    "        return [[layer.feature_size for layer in block.convs] for block in self.blocks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evolutionary algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENAS:\n",
    "    \n",
    "    def __init__(self, pop_size=1):\n",
    "        self.pop_size = pop_size\n",
    "        self.population = [Network() for _ in range(pop_size)]\n",
    "        self.val_bests = []\n",
    "        self.test_bests = []\n",
    "\n",
    "        self.avg_blocks = []\n",
    "        # self.avg_layer_density = []\n",
    "        self.best_val = []\n",
    "        self.best_test = []\n",
    "\n",
    "        self.initialization()\n",
    "\n",
    "    def initialization(self):\n",
    "        print('INITIALIZATION'.center(100, '-'))\n",
    "        for i, network in enumerate(self.population):\n",
    "            print('SPECIMEN ' + str(i+1) + '/' + str(self.pop_size))\n",
    "            try:\n",
    "                network.evaluate()\n",
    "            except:\n",
    "                network.val_score = 0\n",
    "                network.test_score = 0\n",
    "            if i < BEST_LIMIT:\n",
    "                self.val_bests.append((network, 0))\n",
    "                self.val_bests.sort(key=lambda x: x[0].val_score)\n",
    "                self.test_bests.append([network, 0])\n",
    "                self.test_bests.sort(key=lambda x: x[0].test_score)\n",
    "            else:\n",
    "                if network.val_score > self.val_bests[0][0].val_score:\n",
    "                    del self.val_bests[0]\n",
    "                    self.val_bests.append([network, 0])\n",
    "                    self.val_bests.sort(key=lambda x: x[0].val_score)\n",
    "                if network.test_score > self.test_bests[0][0].test_score:\n",
    "                    del self.test_bests[0]\n",
    "                    self.test_bests.append([network, 0])\n",
    "                    self.test_bests.sort(key=lambda x: x[0].test_score)\n",
    "        self.update()         \n",
    "        self.cycle_bests_info()\n",
    "\n",
    "    def update(self):\n",
    "        self.best_val.append(self.val_bests[-1][0].val_score)\n",
    "        self.best_test.append(self.test_bests[-1][0].test_score)\n",
    "\n",
    "        blocks = [len(net.blocks) for net in self.population]\n",
    "        self.avg_blocks.append(sum(blocks)/self.pop_size)\n",
    "\n",
    "\n",
    "    def evolve(self, cycles):\n",
    "        for cycle in range(cycles):\n",
    "            print(('CYCLE ' + str(cycle+1) + '/'+ str(cycles)).center(100, '-'))\n",
    "            new_population = self.crossover(self.selection())\n",
    "            for i, network in enumerate(new_population):\n",
    "                print('SPECIMEN ' + str(i+1) + '/' + str(self.pop_size))\n",
    "                network.mutate()\n",
    "                try:\n",
    "                    network.evaluate()\n",
    "                except:\n",
    "                    network.val_score = 0\n",
    "                    network.test_score = 0\n",
    "                if network.val_score > self.val_bests[0][0].val_score:\n",
    "                    del self.val_bests[0]\n",
    "                    self.val_bests.append((network, cycle+1))\n",
    "                    self.val_bests.sort(key=lambda x: x[0].val_score)\n",
    "                if network.test_score > self.test_bests[0][0].test_score:\n",
    "                    del self.test_bests[0]\n",
    "                    self.test_bests.append([network, cycle+1])\n",
    "                    self.test_bests.sort(key=lambda x: x[0].test_score)\n",
    "            self.population = [sorted(self.population, key=lambda x: x.val_score)[-1]]\n",
    "            self.population.extend(sorted(new_population, key=lambda x: x.val_score)[1:])\n",
    "            self.update()\n",
    "            self.cycle_bests_info()\n",
    "        plt.figure(1)\n",
    "        plt.plot(np.arange(0, cycles+1, 1), self.best_val, 'r', np.arange(0, cycles+1, 1), self.best_test)\n",
    "        plt.show()\n",
    "        plt.figure(2)\n",
    "        plt.plot(self.avg_blocks)\n",
    "        plt.show()\n",
    "            \n",
    "    def selection(self):\n",
    "        new_population = {}\n",
    "        for _ in range(self.pop_size):\n",
    "            tournament = choices(self.population, k=2)\n",
    "            if tournament[0].val_score >= tournament[1].val_score:\n",
    "                if tournament[0] in new_population.keys():\n",
    "                    new_population[tournament[0]] += 1\n",
    "                else:\n",
    "                    new_population[tournament[0]] = 1\n",
    "            else:\n",
    "                if tournament[1] in new_population.keys():\n",
    "                    new_population[tournament[1]] += 1\n",
    "                else:\n",
    "                    new_population[tournament[1]] = 1\n",
    "        return new_population\n",
    "\n",
    "    def crossover(self, population):\n",
    "        population = copy.deepcopy(population)\n",
    "        # One-block specimens\n",
    "        new_population = []\n",
    "        for net, val in population.items():\n",
    "            if len(net.blocks) == 1:\n",
    "                for _ in range(val):\n",
    "                    new_population.append(copy.deepcopy(net))\n",
    "        # Multi-blocks specimens\n",
    "        mb_nets = []\n",
    "        mb_vals = []\n",
    "        for net, val in population.items():\n",
    "            if len(net.blocks) > 1:\n",
    "                mb_nets.append(net)\n",
    "                mb_vals.append(val)\n",
    "        probabilities = [val/sum(mb_vals) for val in mb_vals]\n",
    "        # If only one multi-blocks kind\n",
    "        if len(mb_nets) == 1:\n",
    "            for _ in range(mb_vals[0]):\n",
    "                new_population.append(copy.deepcopy(mb_nets[0]))\n",
    "            return new_population\n",
    "        for i in range(floor((self.pop_size-len(new_population))/2)):\n",
    "            parents = np.random.choice(mb_nets, 2, replace=True, p=probabilities)\n",
    "            cut = randint(1, min([len(network.blocks) for network in parents])-1)\n",
    "            child_1 = Network([copy.deepcopy(parents[0].blocks[0:cut]), copy.deepcopy(parents[1].blocks[cut:])])\n",
    "            child_2 = Network([copy.deepcopy(parents[1].blocks[0:cut]), copy.deepcopy(parents[0].blocks[cut:])])\n",
    "            new_population.append(child_1)\n",
    "            new_population.append(child_2)\n",
    "        # If odd number left\n",
    "        if len(new_population) < self.pop_size:\n",
    "            parents = np.random.choice(mb_nets, 2, replace=True, p=probabilities)\n",
    "            cut = randint(1, min([len(network.blocks) for network in parents])-1)\n",
    "            child_1 = Network([copy.deepcopy(parents[0].blocks[0:cut]), copy.deepcopy(parents[1].blocks[cut:])])\n",
    "            new_population.append(child_1)\n",
    "        return new_population\n",
    "\n",
    "    def cycle_bests_info(self):\n",
    "        print([(round(net.val_score, 5), cycle) for net, cycle in self.val_bests])\n",
    "        print([(round(net.test_score, 5), cycle) for net, cycle in self.test_bests])\n",
    "\n",
    "# sys.stdout = open('results.txt', \"w\")\n",
    "# sys.stdout.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running the script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 20\n",
    "iterations = 50\n",
    "\n",
    "test = ENAS(population_size)\n",
    "test.evolve(iterations)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
